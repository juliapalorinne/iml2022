---
title: "IML Term project"
author: "Julia Palorinne, Pyry Silomaa, Sara Sippola"
output: pdf_document
date: '`r format(Sys.Date(), "%d.%m.%Y")`'
---

# Set-up and data preprosessing

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(kableExtra)
```

```{r load data}
npf <- read.csv("npf_train.csv")
```

```{r preprocess data}

# Dataset names:
# npf          - "Original" data: has class2 with values 0,1 as numeric values, 
#                   columns removed: class4, partlybad, date (moved to rowname)
# npf.fact     - Otherwise the same as npf, but class2 is a factor with levels 0 and 1
# npf.168      - Processed data: Parameters that have different measurement heights have been reduced to height 16.8m
#                   columns removed: Parameters with height that's not 16.8m
# npf.168.fact -  Otherwise the same as npf.168, but class2 is a factor


# Create class2, 0 = nonevent, 1 = event
npf$class2 <- ifelse(npf$class4 == "nonevent", 0, 1)

# Add date as row name
rownames(npf) <- npf[, "date"]

# Select global and 16.8 m high values
npf.168 <- data.frame(npf[, (5:6)], npf[, (13:16)], npf[, (27:30)], 
                  npf[, (41:42)], npf[, (53:54)], npf[, (63:72)],
                  npf[, (83:88)], npf[, (99:105)])


# Remove columns id, date, class4, partlybad from npf
npf <- npf[, -(1:4)]

# Create datasets where class2 is a factor
npf.fact <- npf
npf.fact$class2 <- factor(npf.fact$class2)
npf.168.fact <- npf.168
npf.168.fact$class2 <- factor(npf.168.fact$class2)


# Divide training data into two for training & testing
set.seed(42)
idx <- sample(nrow(npf), nrow(npf)/2)
npf_train <- npf[idx, ]
npf_test <- npf[-idx, ]

```

```{r functions}
# mean squared error
mse <- function(yhat, y) sqrt(mean((y - yhat)**2))

## accuracy
accuracy <- function(pred, y) mean(ifelse(pred >= 0.5, 1, 0) == y)

## perplexity. Force probabilities to [0.995, 0.005]
perplexity <- function(pred, y){
  pred <- ifelse(pred != 0 & pred != 1, pred, ifelse(pred == 0, 0.005, 0.995 ))
  exp(-mean(log(ifelse(y == 1, pred, 1 - pred)))) }

# cross-validate
# split n items into k folds of roughly equal size
kpart <- function(n, k) {
    rep_len(1:k, length.out = n)
}

# Find cross-validation predictions
cv <- function(
               formula, # Formula specifying which variables to use
               data, # Dataset
               model = lm, # Type of model to train (as a function)
               n = nrow(data), # number of rows in the data matrix
               k = min(n, 10), # number of cross-validation folds
               split = kpart(n, k), # the split of n data items into k folds
               ## function to train a model on data
               train = function(data) model(formula, data = data),
               ## function to make predictions on the trained model
               pred = function(model, data) predict(model, newdata = data, type = "raw")[,2]) {
    yhat <- NULL
    for (i in 1:k) {
        ## go through all folds, train on other folds, and make a prediction
        mod <- train(data[split != i, ])
        if (is.null(yhat)) {
            ## initialise yhat to something of correct data type,
            yhat <- pred(mod, data)
        } else {
            yhat[split == i] <- pred(mod, data[split == i, ])
        }
    }
    yhat # finally, output cross-validation predictions
}
# loocv <- function(
#                formula, # Formula specifying which variables to use
#                data, # Dataset
#                model = lm, # Type of model to train (as a function)
#                ## function to train a model on data
#                train = function(data) model(formula, data = data),
#                ## function to make predictions on the trained model
#                pred = function(model, data) predict(model, newdata = data, type = "raw")[,2]) {
#     yhat <- NULL
#     for (i in 1:nrow(data)) {
#         ## go through all stations, train on other stations, and make a prediction
#         mod <- train(data[-i, ])
#         if (is.null(yhat)) {
#             ## initialise yhat to something of correct data type,
#             yhat <- pred(mod, data)
#         } else {
#             yhat[i] <- pred(mod, data[i, ])
#         }
#     }
#     yhat # finally, output cross-validation predictions
# }
```

# Classifiers

## Testing classifiers as they are

### Naive Bayes

```{r naive bayes}
library(e1071)
nb.fit <- naiveBayes(class2 ~ . , data = npf_train, laplace = 1)
nb.pred.cv <- cv(class2 ~ ., npf, naiveBayes) # Hidas prosessi, tehdään siksi vaan kerran
nb_acc <- data.frame(train = accuracy(predict(nb.fit, newdata = npf_train, type = "raw")[,2], npf_train$class2),
                     test = accuracy(predict(nb.fit, newdata = npf_test, type = "raw")[,2], npf_test$class2),
                     CV = accuracy(nb.pred.cv, npf$class2))
# Kaikkiin tulee Inf
nb_perp <- data.frame(train = perplexity(predict(nb.fit, newdata = npf_train, type = "raw")[,2], npf_train$class2),
                      test = perplexity(predict(nb.fit, newdata = npf_test, type = "raw")[,2], npf_test$class2),
                      CV = perplexity(nb.pred.cv, npf$class2))
kable(cbind(nb_acc,
            nb_perp)) %>%
  add_header_above(c("Accuracy" = 3, "Perplexity" = 3))
```

### LDA
```{r lda}
library(MASS)
lda.fit <- lda(class2 ~ . , data = npf_train)
# Cross-validation parametrit
n = nrow(npf) # number of rows in the data matrix
k = min(n, 10) # number of cross-validation folds
split = kpart(n, k) # the split of n data items into k folds
lda.pred.cv <- rep(0,n)
# cv
for (i in 1:k) {
  ## go through all folds, train on other folds, and make a prediction
  mod <- lda(class2 ~ ., npf[split != i, ])
  lda.pred.cv[split == i] <- predict(mod, npf[split == i, ])$posterior[,2]
}
lda_acc <- data.frame(train = accuracy(predict(lda.fit, newdata = npf_train)$posterior[,2], npf_train$class2),
                      test = accuracy(predict(lda.fit, newdata = npf_train)$posterior[,2], npf_test$class2),
                      CV = accuracy(lda.pred.cv, npf$class2))
lda_perp <- data.frame(train = perplexity(predict(lda.fit, newdata = npf_train)$posterior[,2], npf_train$class2),
                      test = perplexity(predict(lda.fit, newdata = npf_train)$posterior[,2], npf_test$class2),
                      CV = perplexity(lda.pred.cv, npf$class2))
kable(cbind(lda_acc,
            lda_perp)) %>%
  add_header_above(c("Accuracy" = 3, "Perplexity" = 3))
```

### QDA
```{r qda}
library(MASS)
qda.fit <- qda(class2 ~ . , data = npf_train)
# Cross-validation parametrit
n = nrow(npf) # number of rows in the data matrix
k = min(n, 10) # number of cross-validation folds
split = kpart(n, k) # the split of n data items into k folds
qda.pred.cv <- rep(0,n)
# cv
for (i in 1:k) {
  ## go through all folds, train on other folds, and make a prediction
  mod <- qda(class2 ~ ., npf[split != i, ])
  qda.pred.cv[split == i] <- predict(mod, npf[split == i, ])$posterior[,2]
}
qda_acc <- data.frame(train = accuracy(predict(qda.fit, newdata = npf_train)$posterior[,2], npf_train$class2),
                      test = accuracy(predict(qda.fit, newdata = npf_train)$posterior[,2], npf_test$class2),
                      CV = accuracy(qda.pred.cv, npf$class2))
# Taas Inf :(
qda_perp <- data.frame(train = perplexity(predict(qda.fit, newdata = npf_train)$posterior[,2], npf_train$class2),
                      test = perplexity(predict(qda.fit, newdata = npf_train)$posterior[,2], npf_test$class2),
                      CV = perplexity(qda.pred.cv, npf$class2))
kable(cbind(qda_acc,
            qda_perp)) %>%
  add_header_above(c("Accuracy" = 3, "Perplexity" = 3))
```

### GLM
```{r glm, warning=FALSE}
mod1<-glm(class2~., npf, family=binomial(link="logit"))
mod2<-glm(class2~., npf, family=binomial(link="probit"))
plot(mod1)
prob1<-predict(mod1, npf, type="response")
pred1<-c()
perp1<-c()
for(i in 1:dim(npf)[1]){
  if(prob1[i]>=0.5){
    pred1<-c(pred1,1)
  } else{
    pred1<-c(pred1,0)
  }
  if(npf$class2[i]==1){
    perp1<-c(perp1,prob1[i])
  } else{
    perp1<-c(perp1,1-prob1[i])
  }
}
mean(pred1==npf$class2)
exp(-mean(perp1))
```

### Lasso / Ridge
```{r lassoridge, message=FALSE}
library(glmnet)
mod3<-cv.glmnet(x=as.matrix(npf[,1:100]), y=npf[,101],alpha=1, family="binomial", type.measure="class")
mod4<-cv.glmnet(x=as.matrix(npf[,1:100]), y=npf[,101],alpha=0, family="binomial", type.measure = "class")
mod3a<-glmnet(x=as.matrix(npf[,1:100]), y=npf[,101],alpha=1, family="binomial", lambda=mod3$lambda.min)
coef(mod3)
plot(mod3a)
plot(mod3$glmnet.fit, xvar="lambda")
prob3a<-predict(mod3a, newx=as.matrix(npf[,1:100]), type="response")
pred3a<-c()
perp3a<-c()
for(i in 1:dim(npf)[1]){
  if(prob3a[i]>=0.5){
    pred3a<-c(pred3a,1)
  } else{
    pred3a<-c(pred3a,0)
  }
  if(npf$class2[i]==1){
    perp3a<-c(perp3a,prob3a[i])
  } else{
    perp3a<-c(perp3a,1-prob3a[i])
  }
}
mean(pred3a==npf$class2)
exp(-mean(perp3a))
mod4a<-glmnet(x=as.matrix(npf[,1:100]), y=npf[,101],alpha=0, family="binomial", lambda=mod4$lambda.min)
plot(mod4a)
plot(mod4$glmnet.fit, xvar="lambda")
prob4a<-predict(mod4a, newx=as.matrix(npf[,1:100]), type="response")
pred4a<-c()
perp4a<-c()
for(i in 1:dim(npf)[1]){
  if(prob4a[i]>=0.5){
    pred4a<-c(pred4a,1)
  } else{
    pred4a<-c(pred4a,0)
  }
  if(npf$class2[i]==1){
    perp4a<-c(perp4a,prob4a[i])
  } else{
    perp4a<-c(perp4a,1-prob4a[i])
  }
}
mean(pred4a==npf$class2)
exp(-mean(perp4a))
```

### SVM
```{r svm, warning=FALSE}
modsv<-tune(svm, class2~., data=npf.fact, kernel="linear", ranges=list(cost=c(0.001, 0.01, 0.1, 1, 2, 5)))
modsvm<-svm(class2~., data=npf.fact, kernel="linear", scale=FALSE, cost=0.001,probability=TRUE)
predsv<-predict(modsvm,newdata=npf.fact)
predsv2<-predict(modsvm,newdata=npf.fact,probability = T)
probsv<-attr(predsv2, "probabilities")
perpsv<-c()
for(i in 1:dim(npf)[1]){
  if(npf$class2[i]==0){
    perpsv<-c(perpsv, probsv[i,2])
  } else{
    perpsv<-c(perpsv, probsv[i,1])
  }
  }
mean(predsv==npf$class2)
exp(-mean(log(perpsv)))
```

\newpage

# Preprocessing data

## Correlation

Looking at the correlation matrix as it was presented in the solutions to Exercise set 1, it is clear that the measurements of the same thing at different heights correlate, as do some of the radiation-related parameters.

```{r correlation, message=FALSE}
library(corrplot)

# Calculate the correlation matrix
cm <- cor(npf[, endsWith(colnames(npf), ".mean")])

# Remove .mean from column and row names.
colnames(cm) <- rownames(cm) <- sapply(colnames(cm), function(s) gsub(".mean", "", s))

# Order variables by 1st principal component (PCA later in the course!)
corrplot(cm, order = "FPC", tl.cex = 0.5, tl.col = "black")
```

\newpage

### Correlation between measurements at different heights

Looking at the numeric values, we see that the measurements at different heights have strong positive correlation.

```{r correlation at different heights, message=FALSE}
# Korrelaatiomatriisi
cm <- cor(npf[, endsWith(colnames(npf), ".mean")])
# Remove .mean from column and row names.
colnames(cm) <- rownames(cm) <- sapply(colnames(cm), function(s) gsub(".mean", "", s))
# Muuttujakohtaiset korrelaatiot (kun enemmän kuin yksi muuttuja, jolla sama alkuosa)
kable(cm[startsWith(colnames(cm), "CO2"), startsWith(colnames(cm), "CO2")],
      caption = "Correlation (CO2)") %>%
  kable_styling()
kable(cm[startsWith(colnames(cm), "H2O"), startsWith(colnames(cm), "H2O")],
      caption = "Correlation (H20)") %>%
  kable_styling()
kable(cm[startsWith(colnames(cm), "NO") & !startsWith(colnames(cm), "NOx"), startsWith(colnames(cm), "NO") & !startsWith(colnames(cm), "NOx")],
      caption = "Correlation (NO)") %>%
  kable_styling()
kable(cm[startsWith(colnames(cm), "NOx"), startsWith(colnames(cm), "NOx")],
      caption = "Correlation (NOx)") %>%
  kable_styling()
kable(cm[startsWith(colnames(cm), "O3"), startsWith(colnames(cm), "O3")],
      caption = "Correlation (O3)") %>%
  kable_styling()
kable(cm[startsWith(colnames(cm), "RHIRGA"), startsWith(colnames(cm), "RHIRGA")],
      caption = "Correlation (RHIRGA)") %>%
  kable_styling()
kable(cm[startsWith(colnames(cm), "T"), startsWith(colnames(cm), "T")],
      caption = "Correlation (T)") %>%
  kable_styling()
```

\newpage

### Measurement heights

The measurement height 16.8m is the only one with all measurements. Because of this and the correlation between the measurements at different heights, we choose to discard measurements heights other than 16.8m.

```{r muuttujakorkeudet, message=FALSE}
# Tunnistetaan, miltä korkeudelta on otettu mitäkin mittauksia
# Sarakkeet
cols <- unname(sapply(colnames(npf[endsWith(colnames(npf), ".mean")]), function(s) gsub(".mean", "", s)))
# Taulukko muuttujista eri korkeuksissa (vain niille muuttujille, joista mittauksia eri korkeuksissa)
kable(data.frame(dm.42 = c(sort(cols[endsWith(cols, "42")])[1:6], NA, sort(cols[endsWith(cols, "42")])[7]),
                                dm.84 = c(NA, sort(cols[endsWith(cols, "84")])[1:5], NA, sort(cols[endsWith(cols, "84")])[6]),
                                dm.168 = c(sort(cols[endsWith(cols, "168")])),
                                dm.336 = c(sort(cols[endsWith(cols, "336")])[1:4], NA, sort(cols[endsWith(cols, "336")])[5], NA, NA),
                                dm.504 = c(sort(cols[endsWith(cols, "504")])[1:6], NA, sort(cols[endsWith(cols, "504")])[7]),
                                dm.672 = c(NA, NA, sort(cols[endsWith(cols, "672")])[2:5], NA, sort(cols[endsWith(cols, "672")])[6])),
      caption = "Measurements at different heights: What measurements have been done at particular heights?") %>%
  kable_styling()
```